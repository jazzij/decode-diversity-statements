{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manalais\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\manalais\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from collections import Counter\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "import difflib\n",
    "import pandas as pd\n",
    "nltk.download('words')\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster=LancasterStemmer()\n",
    "\n",
    "from nltk.tag import pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "vandalism\n",
      "violently\n",
      "condolences\n",
      "slavery\n",
      "antiracist\n",
      "kneeling\n",
      "blacklivesmatter\n",
      "anti-racism\n",
      "inequalities\n",
      "identities\n",
      "shooting\n",
      "protesting\n",
      "inequity\n",
      "died\n",
      "violent\n",
      "struggle\n",
      "activities\n",
      "anti-racist\n",
      "minority\n",
      "loss\n",
      "force\n",
      "humanity\n",
      "killed\n",
      "grief\n",
      "inequities\n",
      "white \n",
      "voices\n",
      "pain\n",
      "systemic\n",
      "minneapolis\n",
      "discrimination\n",
      "american\n",
      "respect\n",
      "arbery\n",
      "action\n",
      "social\n",
      "lives\n",
      "racial\n",
      "color\n",
      "americans\n",
      "ahmaud\n",
      "black\n",
      "anger\n",
      "values\n",
      "inclusive\n",
      "commitment\n",
      "pandemic\n",
      "past\n",
      "taylor\n",
      "life\n",
      "breonna\n",
      "issues\n",
      "rights\n",
      "race\n",
      "right\n",
      "fear\n",
      "protests\n",
      "challenges\n",
      "deaths\n",
      "hate\n",
      "officers\n",
      "sadness\n",
      "killing\n",
      "injustices\n",
      "video\n",
      "equality\n",
      "civil\n",
      "oppression\n",
      "crisis\n",
      "killings\n",
      "policies\n",
      "protest\n",
      "victims\n",
      "inequality\n",
      "murder\n",
      "ethnicity\n",
      "skin\n",
      "government\n",
      "underrepresented\n",
      "unrest\n",
      "hurt\n",
      "frustration\n",
      "minnesota\n",
      "angry\n",
      "movement\n",
      "african-american\n",
      "privilege\n",
      "tragedies\n",
      "mourn\n",
      "murdered\n",
      "arrested\n",
      "demonstrations\n",
      "problem\n",
      "historically\n",
      "unarmed\n",
      "vulnerable\n",
      "mourning\n",
      "threat\n",
      "recently\n",
      "suffered\n",
      "advocacy\n",
      "anti-asian\n",
      "unprecedented\n",
      "success\n",
      "cases\n",
      "aware\n",
      "urgent\n",
      "represent\n",
      "pursuit\n",
      "criminal\n",
      "respectful\n",
      "unjust\n",
      "posts\n",
      "George\n",
      "Floyd\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "IMPORT TEXT FILE\n",
    "'''\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "textdir = os.path.join(current_dir)\n",
    "filename = \"uniquewordslist.txt\"\n",
    "\n",
    "text = []\n",
    "with open(os.path.join(textdir, filename), 'r') as file:\n",
    "        text = file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Finding Hashtags and @mentions\n",
    "'''\n",
    "\n",
    "import re\n",
    "hashtags = re.findall(r'(#\\w+)', text)\n",
    "mentions = re.findall(r'(@\\w+)', text)\n",
    "print(hashtags)\n",
    "print(mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['memory', 'vandalism', 'violently', 'condolences', 'slavery', 'antiracist', 'kneeling', 'blacklivesmatter', 'anti', 'racism', 'inequalities', 'identities', 'shooting', 'protesting', 'inequity', 'died', 'violent', 'struggle', 'activities', 'anti', 'racist', 'minority', 'loss', 'force', 'humanity', 'killed', 'grief', 'inequities', 'white', 'voices', 'pain', 'systemic', 'minneapolis', 'discrimination', 'american', 'respect', 'arbery', 'action', 'social', 'lives', 'racial', 'color', 'americans', 'ahmaud', 'black', 'anger', 'values', 'inclusive', 'commitment', 'pandemic', 'past', 'taylor', 'life', 'breonna', 'issues', 'rights', 'race', 'right', 'fear', 'protests', 'challenges', 'deaths', 'hate', 'officers', 'sadness', 'killing', 'injustices', 'video', 'equality', 'civil', 'oppression', 'crisis', 'killings', 'policies', 'protest', 'victims', 'inequality', 'murder', 'ethnicity', 'skin', 'government', 'underrepresented', 'unrest', 'hurt', 'frustration', 'minnesota', 'angry', 'movement', 'african', 'american', 'privilege', 'tragedies', 'mourn', 'murdered', 'arrested', 'demonstrations', 'problem', 'historically', 'unarmed', 'vulnerable', 'mourning', 'threat', 'recently', 'suffered', 'advocacy', 'anti', 'asian', 'unprecedented', 'success', 'cases', 'aware', 'urgent', 'represent', 'pursuit', 'criminal', 'respectful', 'unjust', 'posts', 'George', 'Floyd']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TOKENIZE TEXT\n",
    "'''\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\") #regex to get all words, including numbers, but not punctuaction\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "print(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'vandalism',\n",
       " 'violently',\n",
       " 'condolences',\n",
       " 'slavery',\n",
       " 'antiracist',\n",
       " 'kneeling',\n",
       " 'blacklivesmatter',\n",
       " 'anti',\n",
       " 'racism',\n",
       " 'inequalities',\n",
       " 'identities',\n",
       " 'shooting',\n",
       " 'protesting',\n",
       " 'inequity',\n",
       " 'died',\n",
       " 'violent',\n",
       " 'struggle',\n",
       " 'activities',\n",
       " 'anti',\n",
       " 'racist',\n",
       " 'minority',\n",
       " 'loss',\n",
       " 'force',\n",
       " 'humanity',\n",
       " 'killed',\n",
       " 'grief',\n",
       " 'inequities',\n",
       " 'white',\n",
       " 'voices',\n",
       " 'pain',\n",
       " 'systemic',\n",
       " 'minneapolis',\n",
       " 'discrimination',\n",
       " 'american',\n",
       " 'respect',\n",
       " 'arbery',\n",
       " 'action',\n",
       " 'social',\n",
       " 'lives',\n",
       " 'racial',\n",
       " 'color',\n",
       " 'americans',\n",
       " 'ahmaud',\n",
       " 'black',\n",
       " 'anger',\n",
       " 'values',\n",
       " 'inclusive',\n",
       " 'commitment',\n",
       " 'pandemic',\n",
       " 'past',\n",
       " 'taylor',\n",
       " 'life',\n",
       " 'breonna',\n",
       " 'issues',\n",
       " 'rights',\n",
       " 'race',\n",
       " 'right',\n",
       " 'fear',\n",
       " 'protests',\n",
       " 'challenges',\n",
       " 'deaths',\n",
       " 'hate',\n",
       " 'officers',\n",
       " 'sadness',\n",
       " 'killing',\n",
       " 'injustices',\n",
       " 'video',\n",
       " 'equality',\n",
       " 'civil',\n",
       " 'oppression',\n",
       " 'crisis',\n",
       " 'killings',\n",
       " 'policies',\n",
       " 'protest',\n",
       " 'victims',\n",
       " 'inequality',\n",
       " 'murder',\n",
       " 'ethnicity',\n",
       " 'skin',\n",
       " 'government',\n",
       " 'underrepresented',\n",
       " 'unrest',\n",
       " 'hurt',\n",
       " 'frustration',\n",
       " 'minnesota',\n",
       " 'angry',\n",
       " 'movement',\n",
       " 'african',\n",
       " 'american',\n",
       " 'privilege',\n",
       " 'tragedies',\n",
       " 'mourn',\n",
       " 'murdered',\n",
       " 'arrested',\n",
       " 'demonstrations',\n",
       " 'problem',\n",
       " 'historically',\n",
       " 'unarmed',\n",
       " 'vulnerable',\n",
       " 'mourning',\n",
       " 'threat',\n",
       " 'recently',\n",
       " 'suffered',\n",
       " 'advocacy',\n",
       " 'anti',\n",
       " 'asian',\n",
       " 'unprecedented',\n",
       " 'success',\n",
       " 'cases',\n",
       " 'aware',\n",
       " 'urgent',\n",
       " 'represent',\n",
       " 'pursuit',\n",
       " 'criminal',\n",
       " 'respectful',\n",
       " 'unjust',\n",
       " 'posts',\n",
       " 'George',\n",
       " 'Floyd']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Remove punctuation\n",
    "'''\n",
    "\n",
    "punctuations=\"\\\"!#â$%&'()*+,-./:;<=>?@[\\]^_`{|}~–\"\n",
    "for word in tokens:\n",
    "    if word in punctuations:\n",
    "        tokens.remove(word)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('memory', 'NN'), ('vandalism', 'NN'), ('violently', 'RB'), ('condolences', 'VBZ'), ('slavery', 'JJ'), ('antiracist', 'NN'), ('kneeling', 'VBG'), ('blacklivesmatter', 'NN'), ('anti', 'JJ'), ('racism', 'NN'), ('inequalities', 'NNS'), ('identities', 'VBZ'), ('shooting', 'VBG'), ('protesting', 'VBG'), ('inequity', 'NN'), ('died', 'VBD'), ('violent', 'JJ'), ('struggle', 'NN'), ('activities', 'NNS'), ('anti', 'VBP'), ('racist', 'JJ'), ('minority', 'NN'), ('loss', 'NN'), ('force', 'NN'), ('humanity', 'NN'), ('killed', 'VBN'), ('grief', 'JJ'), ('inequities', 'NNS'), ('white', 'JJ'), ('voices', 'NNS'), ('pain', 'VBP'), ('systemic', 'JJ'), ('minneapolis', 'NN'), ('discrimination', 'NN'), ('american', 'JJ'), ('respect', 'NN'), ('arbery', 'DT'), ('action', 'NN'), ('social', 'JJ'), ('lives', 'VBZ'), ('racial', 'JJ'), ('color', 'NN'), ('americans', 'VBZ'), ('ahmaud', 'JJ'), ('black', 'JJ'), ('anger', 'NN'), ('values', 'NNS'), ('inclusive', 'JJ'), ('commitment', 'NN'), ('pandemic', 'JJ'), ('past', 'NN'), ('taylor', 'NN'), ('life', 'NN'), ('breonna', 'NN'), ('issues', 'NNS'), ('rights', 'NNS'), ('race', 'NN'), ('right', 'JJ'), ('fear', 'NN'), ('protests', 'NNS'), ('challenges', 'VBZ'), ('deaths', 'NNS'), ('hate', 'NN'), ('officers', 'NNS'), ('sadness', 'VBP'), ('killing', 'VBG'), ('injustices', 'NNS'), ('video', 'JJ'), ('equality', 'NN'), ('civil', 'JJ'), ('oppression', 'NN'), ('crisis', 'NN'), ('killings', 'NNS'), ('policies', 'NNS'), ('protest', 'VBP'), ('victims', 'NNS'), ('inequality', 'NN'), ('murder', 'NN'), ('ethnicity', 'NN'), ('skin', 'JJ'), ('government', 'NN'), ('underrepresented', 'VBD'), ('unrest', 'JJ'), ('hurt', 'NN'), ('frustration', 'NN'), ('minnesota', 'NN'), ('angry', 'JJ'), ('movement', 'NN'), ('african', 'JJ'), ('american', 'JJ'), ('privilege', 'NN'), ('tragedies', 'NNS'), ('mourn', 'VBP'), ('murdered', 'VBN'), ('arrested', 'JJ'), ('demonstrations', 'NNS'), ('problem', 'NN'), ('historically', 'RB'), ('unarmed', 'VBD'), ('vulnerable', 'JJ'), ('mourning', 'NN'), ('threat', 'NN'), ('recently', 'RB'), ('suffered', 'VBD'), ('advocacy', 'NN'), ('anti', 'JJ'), ('asian', 'JJ'), ('unprecedented', 'JJ'), ('success', 'NN'), ('cases', 'NNS'), ('aware', 'JJ'), ('urgent', 'JJ'), ('represent', 'NN'), ('pursuit', 'NN'), ('criminal', 'JJ'), ('respectful', 'NN'), ('unjust', 'JJ'), ('posts', 'NNS'), ('George', 'NNP'), ('Floyd', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "'''tag part of speech first. result is list of (word, tag)'''\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "print(tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['memory', 'vandalism', 'violently', 'condolences', 'slavery', 'antiracist', 'kneel', 'blacklivesmatter', 'anti', 'racism', 'inequality', 'identities', 'shoot', 'protest', 'inequity', 'die', 'violent', 'struggle', 'activity', 'anti', 'racist', 'minority', 'loss', 'force', 'humanity', 'kill', 'grief', 'inequity', 'white', 'voice', 'pain', 'systemic', 'minneapolis', 'discrimination', 'american', 'respect', 'arbery', 'action', 'social', 'live', 'racial', 'color', 'americans', 'ahmaud', 'black', 'anger', 'value', 'inclusive', 'commitment', 'pandemic', 'past', 'taylor', 'life', 'breonna', 'issue', 'right', 'race', 'right', 'fear', 'protest', 'challenge', 'death', 'hate', 'officer', 'sadness', 'kill', 'injustice', 'video', 'equality', 'civil', 'oppression', 'crisis', 'killing', 'policy', 'protest', 'victim', 'inequality', 'murder', 'ethnicity', 'skin', 'government', 'underrepresented', 'unrest', 'hurt', 'frustration', 'minnesota', 'angry', 'movement', 'african', 'american', 'privilege', 'tragedy', 'mourn', 'murder', 'arrested', 'demonstration', 'problem', 'historically', 'unarm', 'vulnerable', 'mourning', 'threat', 'recently', 'suffer', 'advocacy', 'anti', 'asian', 'unprecedented', 'success', 'case', 'aware', 'urgent', 'represent', 'pursuit', 'criminal', 'respectful', 'unjust', 'post']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Stemming and Lemmatization\n",
    "'''\n",
    "\n",
    "    \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "clean_words = []\n",
    "\n",
    "for words, tag in tagged_tokens:\n",
    "    if  not tag.startswith('NNP' or 'NNPS'): # remove propr nouns\n",
    "        if tag.startswith('NN' or 'NNS'):\n",
    "            clean_words.append(lemmatizer.lemmatize(words, pos='n'))\n",
    "        elif tag.startswith('NNP' or 'NNPS'):\n",
    "            clean_words.append(wordnet_lemmatizer.lemmatize(word, pos='n'))\n",
    "        elif tag.startswith('VB' or 'VBP' or 'VBD' or 'VBG' or 'VBP' or 'VBZ'):\n",
    "            clean_words.append(lemmatizer.lemmatize(words, pos='v'))\n",
    "        elif tag.startswith('JJ' or 'JJR' or 'JJS' ):\n",
    "            clean_words.append(lemmatizer.lemmatize(words, pos='a'))\n",
    "        elif tag.startswith('RB' or 'RBR' or 'RBS' or 'RP'):\n",
    "            clean_words.append(lemmatizer.lemmatize(words, pos='r'))\n",
    "        else:\n",
    "            clean_words.append(lemmatizer.lemmatize(words))\n",
    "\n",
    "print(clean_words)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['memory', 'vandalism', 'violently', 'condolences', 'slavery', 'antiracist', 'kneel', 'blacklivesmatter', 'racism', 'inequality', 'identities', 'shoot', 'protest', 'inequity', 'die', 'violent', 'struggle', 'activity', 'racist', 'minority', 'loss', 'force', 'humanity', 'kill', 'grief', 'inequity', 'white', 'voice', 'pain', 'systemic', 'minneapolis', 'discrimination', 'american', 'respect', 'action', 'social', 'live', 'racial', 'color', 'americans', 'black', 'anger', 'value', 'inclusive', 'commitment', 'pandemic', 'past', 'life', 'issue', 'right', 'race', 'right', 'fear', 'protest', 'challenge', 'death', 'hate', 'officer', 'sadness', 'kill', 'injustice', 'video', 'equality', 'civil', 'oppression', 'crisis', 'killing', 'policy', 'protest', 'victim', 'inequality', 'murder', 'ethnicity', 'skin', 'government', 'underrepresented', 'unrest', 'hurt', 'frustration', 'minnesota', 'angry', 'movement', 'african', 'american', 'privilege', 'tragedy', 'mourn', 'murder', 'arrested', 'demonstration', 'problem', 'historically', 'unarm', 'vulnerable', 'mourning', 'threat', 'recently', 'suffer', 'advocacy', 'asian', 'unprecedented', 'success', 'case', 'aware', 'urgent', 'represent', 'pursuit', 'criminal', 'respectful', 'unjust', 'post']\n"
     ]
    }
   ],
   "source": [
    "''' Remove all the stop words'''\n",
    "for word in clean_words:\n",
    "    if word in stopwords.words('english'):\n",
    "        clean_words.remove(word)\n",
    "    if word == 'ahmaud' or word =='taylor' or word =='breonna' or word =='anti' or word =='arbery':\n",
    "        clean_words.remove(word)     \n",
    "print(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['privilege',\n",
       " 'pain',\n",
       " 'post',\n",
       " 'blacklivesmatter',\n",
       " 'represent',\n",
       " 'respectful',\n",
       " 'pandemic',\n",
       " 'angry',\n",
       " 'loss',\n",
       " 'aware',\n",
       " 'system',\n",
       " 'anger',\n",
       " 'respect',\n",
       " 'ethnicity',\n",
       " 'advocacy',\n",
       " 'mourn',\n",
       " 'problem',\n",
       " 'kill',\n",
       " 'demonstration',\n",
       " 'kneel',\n",
       " 'african',\n",
       " 'criminal',\n",
       " 'discrimination',\n",
       " 'threat',\n",
       " 'suffer',\n",
       " 'die',\n",
       " 'civil',\n",
       " 'unarm',\n",
       " 'life',\n",
       " 'unprecedented',\n",
       " 'past',\n",
       " 'officer',\n",
       " 'live',\n",
       " 'hurt',\n",
       " 'humanity',\n",
       " 'skin',\n",
       " 'unrest',\n",
       " 'equality',\n",
       " 'asian',\n",
       " 'recently',\n",
       " 'pursuit',\n",
       " 'condolences',\n",
       " 'challenge',\n",
       " 'victim',\n",
       " 'black',\n",
       " 'oppression',\n",
       " 'fear',\n",
       " 'historically',\n",
       " 'commitment',\n",
       " 'violent',\n",
       " 'minnesota',\n",
       " 'frustration',\n",
       " 'government',\n",
       " 'success',\n",
       " 'inclusive',\n",
       " 'vandalism',\n",
       " 'action',\n",
       " 'underrepresent',\n",
       " 'murder',\n",
       " 'american',\n",
       " 'death',\n",
       " 'slavery',\n",
       " 'memory',\n",
       " 'color',\n",
       " 'force',\n",
       " 'vulnerable',\n",
       " 'sadness',\n",
       " 'arrest',\n",
       " 'right',\n",
       " 'movement',\n",
       " 'shoot',\n",
       " 'video',\n",
       " 'identity',\n",
       " 'tragedy',\n",
       " 'grief',\n",
       " 'value',\n",
       " 'struggle',\n",
       " 'urgent',\n",
       " 'injustice',\n",
       " 'issue',\n",
       " 'hate',\n",
       " 'crisis',\n",
       " 'protest',\n",
       " 'race',\n",
       " 'race',\n",
       " 'minneapolis',\n",
       " 'inequity',\n",
       " 'case',\n",
       " 'voice',\n",
       " 'unjust',\n",
       " 'activity',\n",
       " 'social',\n",
       " 'white',\n",
       " 'antiracist',\n",
       " 'minority',\n",
       " 'inequality',\n",
       " 'policy']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for words in clean_words:\n",
    "    if words == \"racism\":\n",
    "        clean_words[clean_words.index(\"racism\")] = \"race\"   \n",
    "    if words == 'violently':\n",
    "        clean_words[clean_words.index('violently')] = 'violent'\n",
    "    if words == 'identities':\n",
    "        clean_words[clean_words.index('identities')] = 'identity'\n",
    "    if words == 'systemic':\n",
    "        clean_words[clean_words.index('systemic')] = 'system'\n",
    "    if words == 'racial':\n",
    "        clean_words[clean_words.index('racial')] = 'race'\n",
    "    if words == 'killing':\n",
    "        clean_words[clean_words.index('killing')] = 'kill'\n",
    "    if words =='underrepresented':\n",
    "        clean_words[clean_words.index('underrepresented')]  = 'underrepresent'\n",
    "    if words =='americans':\n",
    "        clean_words[clean_words.index('americans')]  = 'american'\n",
    "    if words =='arrested':\n",
    "        clean_words[clean_words.index('arrested')]  = 'arrest' \n",
    "    if words =='mourning':\n",
    "        clean_words[clean_words.index('mourning')]  = 'mourn'\n",
    "    if words =='racist':\n",
    "        clean_words[clean_words.index('racist')]  = 'race'\n",
    "clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['privilege', 'pain', 'post', 'blacklivesmatter', 'represent', 'respectful', 'pandemic', 'angry', 'loss', 'aware', 'system', 'anger', 'respect', 'ethnicity', 'advocacy', 'problem', 'mourn', 'kill', 'demonstration', 'kneel', 'african', 'criminal', 'discrimination', 'threat', 'suffer', 'die', 'civil', 'unarm', 'life', 'unprecedented', 'past', 'officer', 'live', 'hurt', 'humanity', 'skin', 'unrest', 'equality', 'asian', 'recently', 'pursuit', 'condolences', 'challenge', 'victim', 'black', 'oppression', 'fear', 'historically', 'commitment', 'violent', 'minnesota', 'frustration', 'government', 'success', 'inclusive', 'vandalism', 'action', 'underrepresent', 'murder', 'american', 'death', 'slavery', 'memory', 'color', 'force', 'vulnerable', 'sadness', 'arrest', 'right', 'movement', 'shoot', 'video', 'identity', 'tragedy', 'grief', 'value', 'struggle', 'urgent', 'injustice', 'issue', 'hate', 'crisis', 'protest', 'race', 'minneapolis', 'inequity', 'case', 'voice', 'unjust', 'activity', 'social', 'white', 'antiracist', 'minority', 'inequality', 'policy']\n"
     ]
    }
   ],
   "source": [
    "'''Remove duplicate words'''\n",
    "clean_words = list(set(clean_words))  # removes the duplicate words\n",
    "print(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''(Optional) Extra step to get the base words'''\n",
    "# '''The code below returns a list of 20435 lemma words in English'''\n",
    "\n",
    "# words = []\n",
    "# words = []\n",
    "\n",
    "# file = open(r'C:\\Users\\manalais\\Box\\Web Developer\\root_words.txt')\n",
    "# line = file.readlines()\n",
    "# for word in line:\n",
    "#     word = nltk.word_tokenize(word)\n",
    "#     words.append(word)\n",
    "# lemma_words = []\n",
    "# for sublist in words:\n",
    "#     for item in sublist:\n",
    "#         lemma_words.append(item)\n",
    "# print(lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''(Optional Method) Extra step to get the base words'''\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# clean_words = []\n",
    "# porter = PorterStemmer()\n",
    "# for words, tag in tagged_tokens:\n",
    "#     if  not tag.startswith('NNP' or 'NNPS'): # remove propr nouns\n",
    "#         if tag.startswith('NN' or 'NNS'):\n",
    "#             clean_words.append(porter.stem(word))\n",
    "#         elif tag.startswith('VB' or 'VBP' or 'VBD' or 'VBG' or 'VBP' or 'VBZ'):\n",
    "#             clean_words.append(lemmatizer.lemmatize(words, pos='v'))\n",
    "#         elif tag.startswith('JJ' or 'JJR' or 'JJS' ):\n",
    "#             clean_words.append(lemmatizer.lemmatize(words, pos='a'))\n",
    "#         elif tag.startswith('RB' or 'RBR' or 'RBS' or 'RP'):\n",
    "#             clean_words.append(lemmatizer.lemmatize(words, pos='r'))\n",
    "#         else:\n",
    "#             clean_words.append(lemmatizer.lemmatize(words))\n",
    "\n",
    "# print(clean_words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''(Optional Method) Extra step to get the base words'''\n",
    "# # iterates through the lemma words list to unstem the words to their original form\n",
    "# root_words = []\n",
    "# for c in clean_words:\n",
    "#     for w in lemma_words:\n",
    "#         similiarity = difflib.SequenceMatcher(None, c, w).ratio()\n",
    "#         if similiarity > 0.91:\n",
    "#             root_words.append(w)\n",
    "# print('After unstemming: ')\n",
    "# print(root_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for root in clean_words:\n",
    "    dic[root] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'privilege': ['privileged', 'privilege', 'privileges'], 'pain': ['pain', 'paint', 'pains'], 'post': ['post', 'posts', 'posit'], 'blacklivesmatter': ['blacklivesmatter'], 'represent': ['present', 'representing', 'represents', 'represent', 'represented'], 'respectful': ['respectful', 'respectfully'], 'pandemic': ['pandemic', 'pandemics'], 'angry': ['angry'], 'loss': ['los', 'loss'], 'aware': ['aware'], 'system': ['systemic', 'systems', 'system'], 'anger': ['anger', 'danger'], 'respect': ['respect', 'respected', 'respects'], 'ethnicity': ['ethnicity'], 'advocacy': ['advocacy'], 'problem': ['problems', 'problem'], 'mourn': ['mourn', 'mourns'], 'kill': ['kill'], 'demonstration': ['demonstrations', 'demonstration', 'demonstrating'], 'kneel': ['knee', 'kneel', 'kneels'], 'african': ['african'], 'criminal': ['criminal', 'criminals'], 'discrimination': ['discrimination', 'discriminatory', 'nondiscrimination'], 'threat': ['threaten', 'threat', 'treat', 'threats'], 'suffer': ['suffer', 'suffered'], 'die': ['died', 'die', 'dies'], 'civil': ['civil'], 'unarm': [], 'life': ['life'], 'unprecedented': ['unprecedented'], 'past': ['past', 'pat'], 'officer': ['officer', 'officers', 'office', 'offices'], 'live': ['lived', 'lives', 'live', 'alive'], 'hurt': ['hurt', 'hurts'], 'humanity': ['humanity'], 'skin': ['skin', 'sin'], 'unrest': ['unrest'], 'equality': ['equity', 'equality', 'quality', 'inequality'], 'asian': ['asian'], 'recently': ['recent', 'recently'], 'pursuit': ['pursuit'], 'condolences': ['condolences'], 'challenge': ['challenges', 'challenge', 'challenged'], 'victim': ['victims', 'victim'], 'black': ['lack', 'back', 'black', 'blacks'], 'oppression': ['oppression'], 'fear': ['fear', 'far', 'ear', 'fears'], 'historically': ['historical', 'historically'], 'commitment': ['commitment', 'commitments', 'recommitment'], 'violent': ['violent', 'violently'], 'minnesota': ['minnesota'], 'frustration': ['frustration', 'frustrations'], 'government': ['government'], 'success': ['successes', 'success'], 'inclusive': ['inclusive', 'inclusivevt'], 'vandalism': ['vandalism', 'vandals'], 'action': ['action', 'reaction', 'actions', 'inaction', 'fraction'], 'underrepresent': ['underrepresented'], 'murder': ['murder', 'murders', 'murdered'], 'american': ['americans', 'america', 'american'], 'death': ['death', 'deaths'], 'slavery': ['slavery'], 'memory': ['memory', 'emory'], 'color': ['color', 'colour'], 'force': ['force', 'forces', 'forced', 'fore'], 'vulnerable': ['vulnerable'], 'sadness': ['sadness'], 'arrest': ['arrested', 'arrest'], 'right': ['rights', 'right', 'bright', 'wright'], 'movement': ['moment', 'movement'], 'shoot': ['shot'], 'video': ['video', 'videos'], 'identity': ['identity', 'identify'], 'tragedy': ['tragedy'], 'grief': ['grief'], 'value': ['values', 'value', 'valued'], 'struggle': ['struggle', 'struggles', 'struggled'], 'urgent': ['urgent', 'urgently'], 'injustice': ['injustice', 'justice', 'injustices'], 'issue': ['issues', 'issued', 'issue'], 'hate': ['hate'], 'crisis': ['crisis'], 'protest': ['protests', 'protest', 'protect', 'protested'], 'race': ['race', 'races', 'grace'], 'minneapolis': ['minneapolis'], 'inequity': ['equity', 'inequality', 'inequity'], 'case': ['chase', 'case', 'cease', 'cause', 'cases'], 'voice': ['voices', 'voice', 'vice'], 'unjust': ['unjust', 'unjustly'], 'activity': ['activity'], 'social': ['social', 'socially', 'societal'], 'white': ['white'], 'antiracist': ['antiracist', 'antiracism'], 'minority': ['minority'], 'inequality': ['equality', 'inequality', 'inequity'], 'policy': ['policy']}\n",
      "[16, 1, 6, 0, 0, 11, 0, 67, 0, 0, 0, 5, 13, 52, 0, 11, 5, 14, 0, 0, 0, 19, 0, 22, 0, 0, 0, 8, 12, 13, 0, 14, 0, 10, 36, 20, 20, 0, 22, 0, 0, 0, 0, 18, 0, 83, 9, 0, 10, 0, 0, 4, 21, 28, 12, 17, 0, 12, 0, 34, 17, 10, 0, 0, 0, 24, 0, 34, 14, 3, 0, 0, 65, 0, 0, 0, 5, 0, 0, 0, 0, 0, 12, 5, 21, 12, 0, 35, 0, 17, 0, 0, 38, 0, 0, 2, 2, 4, 12, 34, 1, 0, 5, 34, 0, 0, 17, 0, 0, 39, 0, 28, 0, 22, 0, 0, 0, 0, 23, 0, 0, 0, 0, 15, 0, 25, 0, 0, 0, 0, 38, 5, 18, 25, 0, 0, 19, 0, 0, 0, 1, 0, 0, 0, 24, 0, 26, 0, 0, 14, 5, 22, 0, 28, 33, 7, 28, 0, 5, 11, 5, 5, 71, 48, 0, 0, 0, 25, 0, 16, 0, 0, 0, 0, 0, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 14, 0, 0, 19, 0, 0, 0, 0, 0, 0, 0, 23, 0, 2, 0, 0, 0, 0, 0, 17, 18, 12, 0, 16, 40, 11, 24, 0, 0, 14, 0, 0, 10, 14, 16, 0, 10, 24, 0, 0, 19, 0, 38, 0, 36, 18, 30, 27, 22, 0, 24, 36, 0, 29, 2, 16, 33, 35, 0, 0, 2, 39, 24, 29, 30, 13, 17, 15, 0, 27, 20, 38, 0, 26, 26, 26, 16, 16, 9, 6, 15, 36, 30, 19, 24, 29, 2, 9, 19, 15, 34, 56, 15, 17, 32, 12, 20, 15, 20, 15, 20, 22, 0, 0, 22, 10, 14, 34, 42, 31, 25, 27, 40, 5, 25, 21, 24, 22, 0, 0, 0, 0, 23, 34, 0, 0, 0, 26, 0, 15, 16, 0, 38]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "IMPORT TEXT FILE\n",
    "'''\n",
    "import nltk\n",
    "import os\n",
    "filtered_words = []\n",
    "def stop_words(tokens):\n",
    "    \"\"\"\n",
    "    This function is for removing the stopwords from the text file.\n",
    "    Filename: Name of the file\n",
    "    return: filtered_words\n",
    "    \"\"\"\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))  # Creating a List of stopwords\n",
    "    for w in tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_words.append(w)  # Add all words after stopwords have been removed\n",
    "    # print (\"Filtered_words:\",filtered_words )\n",
    "    return filtered_words\n",
    "word_count = []\n",
    "current_dir = os.getcwd()\n",
    "textdir = (r\"C:\\Users\\manalais\\decode-diversity-statements\\tokenText\")\n",
    "for filename in os.listdir(textdir)[:]:\n",
    "    filepath = os.path.join(textdir, filename)\n",
    "    with open(filepath, \"r\") as file:\n",
    "        text = file.read()\n",
    "        tokens = tokenizer.tokenize(text)  # Returns a text as a list of words with punctuations\n",
    "        tokens = [token.lower() for token in tokens if token.isalpha()]  # Changes all the words into lower case        \n",
    "        count = 0\n",
    "        for r in clean_words:\n",
    "            for leaf in tokens:\n",
    "                similiarity = difflib.SequenceMatcher(None, r, leaf).ratio()\n",
    "                if similiarity > 0.90:\n",
    "                    count += 1\n",
    "                    if leaf not in dic[r]:\n",
    "                        dic[r].append(leaf)\n",
    "        word_count.append(count)\n",
    "        \n",
    "    \n",
    "    \n",
    "print(dic)\n",
    "print(word_count)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Create a leaf words list and append all of the leaf words to the dictionary'''\n",
    "\n",
    "# #create a dictionory here assign all the roots to keys and empty list as values\n",
    "# dic = {}\n",
    "# for root in clean_words:\n",
    "#     dic[root] = []\n",
    "    \n",
    "\n",
    "\n",
    "# leaf_list = list(set(leaf_list))  # removes the duplicate words\n",
    "\n",
    "# # This code finds the leaf words and returns it as a list   \n",
    "# for root in clean_words:\n",
    "#     #print(root)\n",
    "#     for leaf in leaf_list:\n",
    "#         #print(leaf)\n",
    "#         similiarity = difflib.SequenceMatcher(None, root, leaf).ratio()\n",
    "#         if similiarity > 0.7:\n",
    "#             dic[root].append(leaf)\n",
    "# print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for value in dic.values():\n",
    "    for i in value:\n",
    "#         if i == 'paint':\n",
    "#             value.remove(i)\n",
    "#         if i == 'posit':\n",
    "#             value.remove(i)\n",
    "#         if i == 'present':\n",
    "#             value.remove(i)\n",
    "#         if i == 'los':\n",
    "#             value.remove(i)\n",
    "#         if i == 'pat':\n",
    "#             value.remove(i)\n",
    "#         if i == 'sin':\n",
    "#             value.remove(i)\n",
    "#         if i == 'lack':\n",
    "#             value.remove(i)\n",
    "#         if i == 'back':\n",
    "#             value.remove(i)\n",
    "#         if i == 'far':\n",
    "#             value.remove(i)\n",
    "#         if i == 'ears':\n",
    "#             value.remove(i)\n",
    "#         if i == 'inclusivevt':\n",
    "#             value.remove(i)\n",
    "#         if i == 'fraction':\n",
    "#             value.remove(i)\n",
    "#         if i == 'reaction':\n",
    "#             value.remove(i)\n",
    "#         if i == 'emory':\n",
    "#             value.remove(i)\n",
    "#         if i == 'fore':\n",
    "#             value.remove(i) \n",
    "#         if i == 'bright':\n",
    "#             value.remove(i)\n",
    "#         if i == 'wright':\n",
    "#             value.remove(i)\n",
    "#         if i == 'identify':\n",
    "#             value.remove(i)\n",
    "#         if i == 'grace':\n",
    "#             value.remove(i)\n",
    "#         if i == 'chase':\n",
    "#             value.remove(i)\n",
    "#         if i == 'ceases':\n",
    "#             value.remove(i)\n",
    "#         if i == 'causes':\n",
    "#             value.remove(i) \n",
    "#         if i == 'vice':\n",
    "#             value.remove(i)\n",
    "#         if i == 'danger':\n",
    "#             value.remove(i)\n",
    "#         if i == 'treat':\n",
    "#             value.remove(i)\n",
    "#         if i == 'quality':\n",
    "#             value.remove(i)\n",
    "#         if i == 'back':\n",
    "#             value.remove(i)\n",
    "#         if i == 'ear':\n",
    "#             value.remove(i)\n",
    "\n",
    "#         if i == 'wright':\n",
    "#             value.remove(i)\n",
    "#         if i == 'cease':\n",
    "#             value.remove(i)\n",
    "#         if i == 'cause':\n",
    "#             value.remove(i)\n",
    "#         if i == 'movement':\n",
    "#             value.remove('moment')\n",
    "#         if i == 'protest':\n",
    "#             value.remove(i)\n",
    "# #\n",
    "#         if i == 'justice':\n",
    "#             value.remove(i)\n",
    "#         if i == 'nondiscrimination':\n",
    "#             value.remove(i)\n",
    "#         if i == 'america':\n",
    "#             value.remove(i)\n",
    "#         if i == 'inaction':\n",
    "#             value.remove(i)\n",
    "        if i == 'knee':\n",
    "            value.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['race', 'races', 'racism', 'racist']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['equality'] = [ 'equality']\n",
    "dic['equality']\n",
    "dic['inequity'] = ['inequity']\n",
    "dic['inequity']\n",
    "dic['officer'] = ['officer', 'officers']\n",
    "dic['officer']\n",
    "dic['race'] = ['race', 'races', 'racism', 'racist']\n",
    "dic['race']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ed41e62bcc54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# + \"|  \" + \"\\033[1m\" + str(count)  + \"\\033[0m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mkey_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dic' is not defined"
     ]
    }
   ],
   "source": [
    "'''Visualize the data'''\n",
    "\n",
    "key_list = []\n",
    "value_list = []\n",
    "\n",
    "# + \"|  \" + \"\\033[1m\" + str(count)  + \"\\033[0m\"\n",
    "for k in dic.keys():\n",
    "    key_list.append(k)\n",
    "for v in dic.values():\n",
    "    value_list.append(v)\n",
    "\n",
    "print(\"\\n\" + \"\\033[1m\" + \"Root and Leaf Plot\".center(60) + \"\\n\")\n",
    "for key,value,count in zip(key_list,value_list,word_count):\n",
    "    print(\"\\033[1m\" + key + \"\\033[0m\" + '| ' + \" \".join(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': ['one'], '3': ['three'], '2': ['two'], '5': ['five'], '4': ['four']}\n"
     ]
    }
   ],
   "source": [
    "d = {'1': ['one'], '3': ['three'], '2': ['two'], '5': ['five'], '4': ['four']}\n",
    "if 'three' not in d['3']:\n",
    "    d['3'].append('three')\n",
    "print(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "IMPORT TEXT FILE\n",
    "'''\n",
    "import nltk\n",
    "import os\n",
    "filtered_words = []\n",
    "def stop_words(tokens):\n",
    "    \"\"\"\n",
    "    This function is for removing the stopwords from the text file.\n",
    "    Filename: Name of the file\n",
    "    return: filtered_words\n",
    "    \"\"\"\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))  # Creating a List of stopwords\n",
    "    for w in tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_words.append(w)  # Add all words after stopwords have been removed\n",
    "    # print (\"Filtered_words:\",filtered_words )\n",
    "    return filtered_words\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "textdir = (r\"C:\\Users\\manalais\\decode-diversity-statements\\tokenText\")\n",
    "for filename in os.listdir(textdir)[:]:\n",
    "    filepath = os.path.join(textdir, filename)\n",
    "    with open(filepath, \"r\") as file:\n",
    "        text = file.read()\n",
    "        tokens = tokenizer.tokenize(text)  # Returns a text as a list of words with punctuations\n",
    "        tokens = [token.lower() for token in tokens if token.isalpha()]  # Changes all the words into lower case        \n",
    "        for rooot in clean_words:\n",
    "            for leaf in tokens:\n",
    "                similiarity = difflib.SequenceMatcher(None, rooot, leaf).ratio()\n",
    "                if similiarity > 0.80:\n",
    "                    if leaf not in d[rooot]:\n",
    "                        d[rooot].append(leaf)\n",
    "              \n",
    "    \n",
    "print(dic)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f', 'c', 'c']\n"
     ]
    }
   ],
   "source": [
    "l=['a','b','c']\n",
    "for i in l:\n",
    "    if i == 'b':\n",
    "        l[l.index('b')] = 'c'\n",
    "    if i == 'a':\n",
    "        l[l.index('a')] = 'f'\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['race', 'violent', 'identity', 'sama']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words = [\"racism\", \"violently\", \"identities\", \"sama\"]\n",
    "for words in (clean_words):\n",
    "    if words == 'racism':\n",
    "        clean_words[clean_words.index('racism')] = 'race'   \n",
    "    if words == 'violently':\n",
    "        clean_words[clean_words.index('violently')] = 'violent'\n",
    "    if words == 'identities':\n",
    "        clean_words[clean_words.index('identities')] = 'identity'\n",
    "    if words == 'systemic':\n",
    "        clean_words[clean_words.index('systemic')] = 'system'\n",
    "    if words == 'racial':\n",
    "        clean_words[clean_words.index('racial')] = 'race'\n",
    "    if words == 'killing':\n",
    "        clean_words[clean_words.index('killing')] = 'kill'\n",
    "    if words =='underrepresented':\n",
    "        clean_words[clean_words.index('underrepresented')]  = 'underrepresent'\n",
    "    if words =='americans':\n",
    "        clean_words[clean_words.index('americans')]  = 'american'\n",
    "    if words =='arrested':\n",
    "        clean_words[clean_words.index('arrested')]  = 'arrest' \n",
    "    if words =='mourning':\n",
    "        clean_words[clean_words.index('mourning')]  = 'mourn'\n",
    "clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
